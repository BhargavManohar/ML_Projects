{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6AnRpEw_pg-r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from support_functions_all import plot_confusion_matrix, generate_features_targets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from support_functions_all import generate_features_targets, plot_confusion_matrix, calculate_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def splitdata_train_test(data, fraction_training):\n",
        "  np.random.seed(0)\n",
        "  np.random.shuffle(data)\n",
        "  split = int(len(data)*fraction_training)\n",
        "  return data[:split], data[split:]\n"
      ],
      "metadata": {
        "id": "rQn1tWhFpoUy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_features_targets(data):\n",
        "\n",
        "  targets = data['class']\n",
        "\n",
        "  features = np.empty(shape=(len(data), 13))\n",
        "  features[:, 0] = data['u-g'] + 1\n",
        "  features[:, 1] = data['g-r']\n",
        "  features[:, 2] = data['r-i']\n",
        "  features[:, 3] = data['i-z']\n",
        "  features[:, 4] = data['ecc']\n",
        "  features[:, 5] = data['m4_u']\n",
        "  features[:, 6] = data['m4_g']\n",
        "  features[:, 7] = data['m4_r']\n",
        "  features[:, 8] = data['m4_i']\n",
        "  features[:, 9] = data['m4_z']\n",
        "\n",
        "  # fill the remaining 3 columns with concentrations in the u, r and z filters\n",
        "  # concentration in u filter\n",
        "  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n",
        "  # concentration in r filter\n",
        "  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n",
        "  # concentration in z filter\n",
        "  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n",
        "\n",
        "  return features, targets\n"
      ],
      "metadata": {
        "id": "61rXOudRpsHi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dtc_predict_actual(data):\n",
        "  # split the data into training and testing sets using a training fraction of 0.7\n",
        "  train, test = splitdata_train_test(data, 0.7)\n",
        "\n",
        "  # generate the feature and targets for the training and test sets\n",
        "  # i.e. train_features, train_targets, test_features, test_targets\n",
        "  train_features, train_targets = generate_features_targets(train)\n",
        "  test_features, test_targets = generate_features_targets(test)\n",
        "\n",
        "  # instantiate a decision tree classifier\n",
        "  dtc = DecisionTreeClassifier()\n",
        "\n",
        "  # train the classifier with the train_features and train_targets\n",
        "  dtc.fit(train_features, train_targets)\n",
        "\n",
        "  # get predictions for the test_features\n",
        "  predictions = dtc.predict(test_features)\n",
        "\n",
        "  # return the predictions and the test_targets\n",
        "  return predictions, test_targets\n"
      ],
      "metadata": {
        "id": "hKqwtBoZpwbp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(predicted_classes, actual_classes):\n",
        "  return sum(predicted_classes == actual_classes)/len(actual_classes)"
      ],
      "metadata": {
        "id": "Rb8fCLJMqTbJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest implementation\n",
        "def rf_predict_actual(data, n_estimators):\n",
        "  # generate the features and targets\n",
        "  features, targets = generate_features_targets(data)\n",
        "\n",
        "  # instantiate a random forest classifier\n",
        "  rfc = RandomForestClassifier(n_estimators=n_estimators)\n",
        "\n",
        "  # get predictions using 10-fold cross validation with cross_val_predict\n",
        "  predicted = cross_val_predict(rfc, features, targets, cv=10)\n",
        "\n",
        "  # return the predictions and their actual classes\n",
        "  return predicted, targets"
      ],
      "metadata": {
        "id": "Rs3f9wgSrucq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "  data = np.load('galaxy_catalogue.npy')\n",
        "\n",
        "  predicted_class, actual_class = dtc_predict_actual(data)\n",
        "\n",
        "  # Print some of the initial results\n",
        "  print(\"Some initial results...\\n   predicted,  actual\")\n",
        "  for i in range(10):\n",
        "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))\n",
        ""
      ],
      "metadata": {
        "id": "LcgNduSUp2Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # split the data\n",
        "  features, targets = generate_features_targets(data)\n",
        "\n",
        "  # train the model to get predicted and actual classes\n",
        "  dtc = DecisionTreeClassifier()\n",
        "  predicted = cross_val_predict(dtc, features, targets, cv=10)\n",
        "\n",
        "  # calculate the model score using your function\n",
        "  model_score = calculate_accuracy(predicted, targets)\n",
        "  print(\"Our accuracy score:\", model_score)\n",
        "\n",
        "  # calculate the models confusion matrix using sklearns confusion_matrix function\n",
        "  class_labels = list(set(targets))\n",
        "  model_cm = confusion_matrix(y_true=targets, y_pred=predicted, labels=class_labels)\n",
        "\n",
        "  # Plot the confusion matrix using the provided functions.\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "vXPTcmW9qUgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  # get the predicted and actual classes\n",
        "  number_estimators = 50              # Number of trees\n",
        "  predicted, actual = rf_predict_actual(data, number_estimators)\n",
        "\n",
        "  # calculate the model score using your function\n",
        "  accuracy = calculate_accuracy(predicted, actual)\n",
        "  print(\"Accuracy score:\", accuracy)\n",
        "\n",
        "  # calculate the models confusion matrix using sklearns confusion_matrix function\n",
        "  class_labels = list(set(actual))\n",
        "  model_cm = confusion_matrix(y_true=actual, y_pred=predicted, labels=class_labels)\n",
        "\n",
        "  # plot the confusion matrix using the provided functions.\n",
        "  plt.figure()\n",
        "  plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6rDaJ5V-sS-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
